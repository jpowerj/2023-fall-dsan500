
```{r}
#| label: ski-plot-binary
#| fig-cap: "*(Example adapted from CS229: Machine Learning, Stanford University)*"
library(tidyverse)
library(lubridate)
sample_size <- 100
day <- seq(ymd('2023-01-01'),ymd('2023-12-31'),by='weeks')
lat_bw <- 5
latitude <- seq(-90, 90, by=lat_bw)
ski_df <- expand_grid(day, latitude)
ski_df <- tibble::rowid_to_column(ski_df, var='obs_id')
#ski_df |> head()
# Data-generating process
lat_cutoff <- 35
ski_df <- ski_df |> mutate(
  near_equator = abs(latitude) <= lat_cutoff,
  northern = latitude > lat_cutoff,
  southern = latitude < -lat_cutoff,
  first_3m = day < ymd('2023-04-01'),
  last_3m = day >= ymd('2023-10-01'),
  middle_6m = (day >= ymd('2023-04-01')) & (day < ymd('2023-10-01')),
  snowfall = 0
)
# Update the non-zero sections
mu_snow <- 10
sd_snow <- 2.5
# How many northern + first 3 months
num_north_first_3 <- nrow(ski_df[ski_df$northern & ski_df$first_3m,])
ski_df[ski_df$northern & ski_df$first_3m, 'snowfall'] = rnorm(num_north_first_3, mu_snow, sd_snow)
# Northerns + last 3 months
num_north_last_3 <- nrow(ski_df[ski_df$northern & ski_df$last_3m,])
ski_df[ski_df$northern & ski_df$last_3m, 'snowfall'] = rnorm(num_north_last_3, mu_snow, sd_snow)
# How many southern + middle 6 months
num_south_mid_6 <- nrow(ski_df[ski_df$southern & ski_df$middle_6m,])
ski_df[ski_df$southern & ski_df$middle_6m, 'snowfall'] = rnorm(num_south_mid_6, mu_snow, sd_snow)
# And collapse into binary var
ski_df['good_skiing'] = ski_df$snowfall > 0
# This converts day into an int
ski_df <- ski_df |> mutate(
  day_num = lubridate::yday(day)
)
#print(nrow(ski_df))
ski_sample <- ski_df |> slice_sample(n = sample_size)
ski_sample |> write_csv("assets/ski.csv")
month_vec <- c(ymd('2023-01-01'), ymd('2023-02-01'), ymd('2023-03-01'), ymd('2023-04-01'), ymd('2023-05-01'), ymd('2023-06-01'), ymd('2023-07-01'), ymd('2023-08-01'), ymd('2023-09-01'), ymd('2023-10-01'), ymd('2023-11-01'), ymd('2023-12-01'))
month_labels <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
lat_vec <- c(-90, -60, -30, 0, 30, 60, 90)
ggplot(
  ski_sample,
  aes(
    x=day,
    y=latitude,
    #shape=good_skiing,
    color=good_skiing
  )) +
  geom_point(
    size = g_pointsize / 1.5,
    #stroke=1.5
  ) +
  dsan_theme() +
  labs(
    x = "Time of Year",
    y = "Latitude",
    shape = "Good Skiing?"
  ) +
  scale_shape_manual(name="Good Skiing?", values=c(1, 3)) +
  scale_color_manual(name="Good Skiing?", values=c(cbPalette[1], cbPalette[2]), labels=c("No (Sunny)","Yes (Snowy)")) +
  scale_x_continuous(
    breaks=c(month_vec,ymd('2024-01-01')),
    labels=c(month_labels,"Jan")
  ) +
  scale_y_continuous(breaks=lat_vec)
```

## The Parent Region {.smaller .crunch-title .crunch-ul .crunch-code .crunch-math}

* Starting out: no splits at all, so that $R = \{X_i \mid X_i \in \mathbf{X} \}$
* So we just guess **most frequent class** in the dataset: **bad** skiing

```{r}
#| label: ski-zero-splits
ski_sample |> count(good_skiing)
```

* This gives us $\Pr(\text{Correct Guess} \mid \text{Guess Bad}) = 0.64$
* Since we're not splitting the region up at all (yet), the entropy is just

$$
\mathscr{L}(R_i) = -[(0.64)\log_2(0.64) + (0.36)\log_2(0.36)] \approx 0.9427
$$

## Judging Split Options {.smaller .crunch-title .crunch-ul .crunch-code .crunch-math .fwtables .smaller-math .smaller-inline .crunch-quarto-layout-panel}

Given that $\mathscr{L}(R_P) \approx 0.9427$, let's think through two choices for the first split:

::: {layout="[10,-1,10]" layout-valign="top" layout-align="center"}

::: {#split-choice-left}

<center>
$(f^A = \text{Latitude}$, $s^A = -42.5)$
</center>

$$
\begin{align*}
R_1^A &= \{X_i \mid X_{i,\text{lat}} < -42.5\} \\
R_2^A &= \{X_i \mid X_{i,\text{lat}} \geq -42.5\}
\end{align*}
$$

```{r}
#| label: ski-split-latitude
#| fig-align: center
#| classes: fwt
ski_sample <- ski_sample |> mutate(
  lat_lt_n425 = latitude < -42.5
)
r1a <- ski_sample |> filter(lat_lt_n425) |> summarize(
  good_skiing = sum(good_skiing),
  total = n()
) |> mutate(region = "R1(A)", .before=good_skiing)
r2a <- ski_sample |> filter(lat_lt_n425 == FALSE) |> summarize(
  good_skiing = sum(good_skiing),
  total = n()
) |> mutate(region = "R2(A)", .before=good_skiing)
choice_a_df <- bind_rows(r1a, r2a)
choice_a_df
```

::: {.math-70}

$$
\begin{align*}
\mathscr{L}(R_1^A) &= -\mkern-4mu\left[ \frac{21}{32}\log_2\frac{21}{32} + \frac{11}{32}\log_2\frac{11}{32} \right] \approx 0.9284 \\
\mathscr{L}(R_2^A) &= -\mkern-4mu\left[ \frac{15}{68}\log_2\frac{15}{68} + \frac{53}{68}\log_2\frac{53}{68}\right] \approx 0.7612 \\
\implies \mathscr{L}(A) &= \frac{32}{100}(0.9284) + \frac{68}{100}(0.7612) \approx 0.8147 
% < 0.9427
\end{align*}
$$

:::

:::
::: {#split-choice-right}

<center>
$(f^B = \text{Month}, s^B = \text{October})$
</center>

$$
\begin{align*}
R_1^B &= \{X_i \mid X_{i,\text{month}} < \text{October}\} \\
R_2^B &= \{X_i \mid X_{i,\text{month}} \geq \text{October}\}
\end{align*}
$$

```{r}
#| label: ski-split-month
#| classes: fwt
ski_sample <- ski_sample |> mutate(
  month_lt_oct = day < ymd('2023-10-01')
)
r1b <- ski_sample |> filter(month_lt_oct) |> summarize(
  good_skiing = sum(good_skiing),
  total = n()
) |> mutate(region = "R1(B)", .before=good_skiing)
r2b <- ski_sample |> filter(month_lt_oct == FALSE) |> summarize(
  good_skiing = sum(good_skiing),
  total = n()
) |> mutate(region = "R2(B)", .before=good_skiing)
choice_b_df <- bind_rows(r1b, r2b)
choice_b_df
```

## Decision Trees (W11) {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-math .smaller-math .fwtables .crunch-code .crunch-quarto-figure}

::: {layout="[[2,3],[1,2]]" layout-valign="top" layout-align="center"}

::: {#sk-dt-left}

<center>
**The Estimated Tree:**
</center>

```{python}
#| label: sklearn-ski
import json
import pandas as pd
import numpy as np
import sklearn
from sklearn.tree import DecisionTreeClassifier
sklearn.set_config(display='text')
ski_df = pd.read_csv("assets/ski.csv")
ski_df['good_skiing'] = ski_df['good_skiing'].astype(int)
id_col = ski_df['obs_id']
X = ski_df[['day_num', 'latitude']]
y = ski_df['good_skiing']
dtc = DecisionTreeClassifier(
  max_depth = 1,
  criterion = "entropy"
)
dtc.fit(X, y);
y_pred = pd.Series(dtc.predict(X), name="y_pred")
result_df = pd.concat([id_col,X,y,y_pred], axis=1)
result_df['correct'] = result_df['good_skiing'] == result_df['y_pred']
result_df.to_csv("assets/ski_predictions.csv", index=False)
sklearn.tree.plot_tree(dtc, feature_names = X.columns)
n_nodes = dtc.tree_.node_count
children_left = dtc.tree_.children_left
children_right = dtc.tree_.children_right
feature = dtc.tree_.feature
feat_index = feature[0]
feat_name = X.columns[feat_index]
thresholds = dtc.tree_.threshold
feat_threshold = thresholds[0]
#print(f"Feature: {feat_name}\nThreshold: <= {feat_threshold}")
values = dtc.tree_.value
#print(values)
dt_data = {
  'feat_index': feat_index,
  'feat_name': feat_name,
  'feat_threshold': feat_threshold
}
dt_df = pd.DataFrame([dt_data])
dt_df.to_feather('assets/ski_dt.feather')
```

:::
::: {#sk-dt-right}

<center>
**Performance:**
</center>

```{r}
#| label: sklearn-ski-results
library(tidyverse)
library(arrow)
library(latex2exp)
r1_label <- TeX('$R_1 \\rightarrow +$')
r2_label <- TeX('$R_2 \\rightarrow -$')
# Load the dataset
ski_result_df <- read_csv("assets/ski_predictions.csv")
# Merge dates back in
ski_sample_day_df <- ski_sample |> select(obs_id, day)
ski_result_df <- ski_result_df |> left_join(ski_sample_day_df, by='obs_id')
#print(sort(ski_result_df$day_num))
# Load the DT info
dt_df <- read_feather("assets/ski_dt.feather")
# Here we only have one value, so just read that
# value directly
lat_thresh <- dt_df$feat_threshold
# And here we convert month_vec into a vector of
# day numbers
day_num_vec <- sapply(month_vec, lubridate::yday)
#print(day_num_vec)
ggplot() +
  geom_point(
    data=ski_result_df,
    aes(x=day_num, y=latitude, color=factor(good_skiing), shape=correct),
    size = g_pointsize / 1.5,
    stroke = 1.5
  ) +
  geom_hline(
    yintercept = lat_thresh,
    linetype = "dashed"
  ) +
  geom_rect(
    aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=-42.5, fill='R1'),
    alpha=0.1
  ) +
  geom_rect(
    aes(xmin=-Inf, xmax=Inf, ymin=-42.5, ymax=Inf, fill='R2'),
    alpha=0.1
  ) +
  dsan_theme("half") +
  labs(
    x = "Time of Year",
    y = "Latitude",
    color = "True Class",
    #shape = "Correct?"
  ) +
  scale_shape_manual("DT Result", values=c(1,3), labels=c("Incorrect","Correct")) +
  scale_fill_manual(
    "DT Prediction",
    values=c('R1'=cbPalette[2], 'R2'=cbPalette[1]),
    labels=c('R1'=r1_label, 'R2'=r2_label)
  ) +
  scale_color_manual("True Class", values=c(cbPalette[1], cbPalette[2]), labels=c("Bad (Sunny)","Good (Snowy)")) +
  scale_x_continuous(
    breaks=c(day_num_vec,366),
    labels=c(month_labels,"Jan")
  ) +
  scale_y_continuous(
    breaks=lat_vec
  )
```

:::

```{r}
#| label: ski-acc-vs-entropy
ski_result_df |> count(correct)
```

$$
\begin{align*}
\mathscr{L}(R_1) &= -\left[ \frac{13}{25}\log_2\frac{13}{25} + \frac{12}{25}\log_2\frac{12}{25} \right] \approx 0.999 \\
\mathscr{L}(R_2) &= -\left[ \frac{61}{75}\log_2\frac{61}{75} + \frac{14}{75}\log_2\frac{14}{75} \right] \approx 0.694 \\
%\mathscr{L}(R \rightarrow (R_1, R_2)) &= \Pr(x_i \in R_1)\mathscr{L}(R_1) + \Pr(x_i \in R_2)\mathscr{L}(R_2) \\
\mathscr{L}(R_1, R_2) &= \frac{1}{4}(0.999) + \frac{3}{4}(0.694) \approx 0.77 < 0.827~ðŸ˜»
\end{align*}
$$

:::